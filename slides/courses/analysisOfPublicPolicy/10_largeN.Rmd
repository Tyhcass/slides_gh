---
title: "Method: Large-N Approach"
subtitle: "Analysis of Public Policy: Perspectives and Methods (30700953)"
author: "Yue HU"
institute: "Political Science, Tsinghua University"
# date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: 
      - zh-CN_custom.css
      - styles.css
      - "https://use.fontawesome.com/releases/v5.6.0/css/all.css"
      - "https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css"
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

library(pacman)
p_load(knitr, kableExtra, # dependency
       stringr, arm, car, 
       summarytools,
       broom, tidyverse) # data wrangling
```

class: bottom, inverse

background-image: url("images/court.jpg")
background-position: center
background-size: contain

# Challenging Time

---

## Procedure

1. Drawing a respondent from the audience
1. The statesperson talks.
1. The statesperson queries.
1. The respondent challenges.
1. Preparation (30 sec)
1. The respondent answers.
1. The statesperson answers.

```{r stopwatch, echo = FALSE}
library(countdown)

countdown(minutes = 0,
          seconds = 30,
          play_sound = TRUE)
```

---

## Overview

.right-column[<img src="images/experiment.jpg" height = 300 />]

.left-column[

### About experiment

+ Why
+ What
+ How

]

---

class: inverse, bottom

# Large-N Analysis

---

## Why Large N?

1. Experiment is not practical
    + Esp. in policy analysis
1. Large amount of observed data
1. Well-developed econometric methods

---

## How Large Is Large?

Let's toss a fair coin:

Head or Tail?

.center[<img src="images/toss.gif" height = 350 />]

---

How about 1 million times? How many heads?

--

```{r, tut=FALSE, fig.width=10, fig.height=6, cache=TRUE}
library(emdbook)
library(plotly)
library(here)

m <- list(
  l = 50,
  r = 50,
  b = 10,
  t = 10,
  pad = 4
)
accumulate_by <- function(dat, var) {
  var <- lazyeval::f_eval(var, dat)
  lvls <- plotly:::getLevels(var)
  dats <- map(seq_along(lvls), function(x) {
    cbind(dat[var %in% lvls[seq(1, x)],], frame = lvls[[x]])
  })
  dplyr::bind_rows(dats)
}
d <- do.call(rbind, map(lseq(10, 10000, 300), function(x) {
  d <- data.frame(x = rnorm(x),
                  frame = x / 300,
                  N = x)
  return(d)
}))
dd <- aggregate(data = d, x ~ frame + N, FUN = mean) %>%
  accumulate_by( ~ N)
p <-
  dd %>% plot_ly(
    x =  ~ log10(N),
    y =  ~ x,
    frame =  ~ frame,
    type = "scatter",
    mode = "lines",
    line = list(simplyfy = F, color = "orangered"),
    width = 550,
    height = 350
  ) %>%
  animation_opts(frame = 10,
                 transition = 0,
                 redraw = FALSE) %>%
  config(displayModeBar = F) %>%
  layout(
    xaxis = list(title = "Sample Size (log10)",
                 zeroline = F),
    yaxis = list(
      range = c(-0.7, 0.7),
      title = "Mean",
      zeroline = F
    ),
    autosize = F,
    margin = m
  ) %>%
  animation_slider(hide = T) %>%
  animation_button(
    x = 1,
    xanchor = "right",
    y = 0,
    yanchor = "bottom"
  )
p
# htmltools::save_html(p, here("images/03_mean/Law_of_large_numbers.html"))
```

---

```{r draws, fig.show="animate", animation.hook = 'gifski', fig.width=10, fig.height=8, results = 'hide', cache=TRUE}
library(ggplot2)

lims <- data.frame(min = c(0, 0, 0, 0), 
                   max = c(4, 16, 120, 1200))

cols <- c("brown1", "darkturquoise", "royalblue1", "darkorchid1")

ns <- c("10", "100", "1,000", "10,000")

plot1 <- function(x) {
  d <- map(c(10, 100, 1000, 10000), function(x) {
    data.frame(x = rnorm(x), frame = x)
  })
  
  p <- map(1:4, function(y) {
    ggplot(data = d[[y]], aes(x)) + 
      geom_histogram(binwidth = 0.25,
                     color = "white",
                     fill = cols[y]) +
      theme_light() +
      theme(
        panel.border = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_line(size = 0.2),
        axis.ticks = element_blank(),
        strip.background = element_blank(),
        strip.text.x = element_text(color = "black"),
        axis.text.x = element_blank(),
        plot.title = element_text(hjust = 0.5, size = 12)
      ) +
      guides(fill = FALSE) + labs(x = NULL, y = NULL) +
      scale_y_continuous(expand = c(0, 0),
                         limits = c(lims[y, 1], lims[y, 2])) + xlim(-5, 5) +
      ggtitle(paste0("N=", ns[y]))
  })
  
  
  p <-
    cowplot::plot_grid(p[[1]], p[[2]], p[[3]], p[[4]], 
                       ncol = 2, 
                       align = "hv")
  p
}

map(1:8, function(x) plot1())
```

---

## Law of Large Numbers

As the number of experiments (sample) increases, the ratio of outcomes will converge to the theoretical (population) average.

* Rule of thumb: $> 100 ~ 200$

---

## Large-N Approaches

* Univariate analysis
* Bivariate analysis
* Multivariate analysis

---

## Univariate analysis

.left-column[
Surveying a dorm room, asking the members how many shows they watched in the past week.
The right table is the records:
]

.right-column[
```{r data}
showWatching <- tibble(Student_ID = paste0("201999", sample(1000:9000, size = 7)), Episodes = c(1, 1, 1, 2, 3, 3, 4))

kable(showWatching, "html", align = "cl")%>%
  kable_styling(full_width = TRUE, font_size = 25)
```
]

???

Let's say we'll test a school policy of Internet access management. 
To do so, researchers surveyed a dorm room, asking the members how many shows they watched in the past week.

---

## How to Describe This Variable

+ Given the list: (1, 1, 1, 2, 3, 3, 4)

--

+ Mean: $\frac{1 + 1 + 1 + 2 + 3 + 3 + 4}{7} = \frac{15}{7} \approx 2.143.$

--

+ Median: 1, 1, 1, .magenta[2], 3, 3, 4

--

+ Mode: three .magenta[1]s, one 2, two 3s, and one 4.

---

## Relations among These Ways

Let's Expand the data to 1000 students.

```{r fig.align="center", fig.height=6}
set.seed(114)

df_var <- data.frame(x = sample(1:10, size = 1000, replace = TRUE))

ggplot(data = df_var, aes(x)) +
  geom_bar() +
  ylab("") + xlab("") +
  scale_x_discrete(limit = 1:10) +
  geom_vline(xintercept = as.numeric(c(mean(df_var$x), 
                            names(sort(-table(df_var$x)))[1],
                            median(df_var$x))), color = 1:3) +
  annotate("text", x = as.numeric(names(sort(-table(df_var$x)))[1]) - 0.7, y = 100, label = "Mode") + 
  annotate("text", x = mean(df_var$x) + 0.5, y = 110, label = "Mean") +
  annotate("text", x = median(df_var$x) - 0.5, y = 110, label = "Median")
```

---

## Mean, Median, or Mode?

```{r distribution, fig.align='center'}
df_var <- data.frame(x = rnorm(10000, mean = 0, sd = 1),
                     y = c(rbeta(9900, shape1 = 5, shape2 = 2), rep(1.5, 100)),
                     z = rnorm(10000, mean = 10, sd = 1),
                     w = rbinom(10000, 1, .5)) %>%
                       mutate(z = w * x + (1 - w) * z) %>%
                         select(x, y, z) %>%
                           gather(var, value)

ggplot(df_var, aes(value)) +
  geom_histogram() +
  facet_wrap(~ var, scales = "free") +
  xlab("") + ylab("")
```

---

## Moments of A Distribution

### Distribution

How much of it there is in each place or at each time.

--

### Moments

A specific quantitative measure of the shape.

.small[
0th. Total probability  
1st. Mean/median/mode  
2ed. Variance  
3id. Skewness  
4th. Kurtosis (tailedness)
]

---

## Primary Moments

Mean: $\mu_x = \frac{\sum X_i}{N};$  
Variance: $\sigma^2_x = E[(X - \mu_x)^2].$

```{r meanVariance, fig.height = 5, fig.align="center"}
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) +
  stat_function(colour = "red", fun = dnorm, n = 101, args = list(mean = 0, sd = 1)) + 
  stat_function(colour = "blue", fun = dnorm, n = 101, args = list(mean = 0.5, sd = 1.5)) +
  ylab("") + xlab("") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "blue") +
  annotate("text", x = -1.2, y = .35, label = "Mean = 0\n SD = 1") + 
  annotate("text", x = 2.5, y = .2, label = "Mean = 0.5\n SD = 1.5")
```

---

Skewness: $\gamma_x = E[(\frac{X - \mu_x}{\sigma})^3].$

```{r skewness, fig.align='center'}
ggplot(data = data.frame(x = c(-.5, 1.5)), aes(x)) +
  stat_function(colour = "red", fun = dbeta, n = 101, args = list(shape1 = 5, shape2 = 2)) + 
  stat_function(colour = "blue", fun = dbeta, n = 101, args = list(shape1 = 2, shape2 = 5)) +
  ylab("") + xlab("") +
  annotate("text", x = -0.125, y = 1.5, label = "Right skewed") + 
  annotate("text", x = 1.125, y = 1.5, label = "Left skewed")
```

---

Kurtosis: $\kappa_x = E[(\frac{X - \mu_X}{\sigma})^4].$

```{r kurtosis, fig.align='center'}
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) +
  stat_function(colour = "darkgreen", fun = dnorm, n = 101, args = list(mean = 0, sd = .5)) + 
  stat_function(colour = "red", fun = dnorm, n = 101, args = list(mean = 0, sd = 1)) + 
  stat_function(colour = "blue", fun = dnorm, n = 101, args = list(mean = 0, sd = 2)) +
  ylab("") + xlab("") +
  annotate("text", x = 1.2, y = .6, label = "Leptokurtic") +
  annotate("text", x = 2.25, y = .3, label = "Mesokurtic (Normal)") + 
  annotate("text", x = 3.5, y = .1, label = "Platykurtic")
```

---

class: small

## Descriptive Statistics

```{r descriptive}
library(summarytools)

print(dfSummary(
  select(tobacco, gender, BMI, disease),
  valid.col = FALSE,
  na.col = FALSE,
  silent = TRUE,
  plain.ascii = FALSE,
  headings = FALSE,
  graph.magnif = 0.75
),
method = 'render',
footnote = NA)
```

---

## Binary Analysis

Relations between variables

```{r crosstable}
print(
  ctable(mtcars$gear, mtcars$cyl, prop = 'n', totals = FALSE),
  headings = FALSE,
  method = "render",
  footnote = NA
)
```

---

## Scatter plot

```{r scatter}
ggplot(mtcars, aes(wt, mpg)) +
  geom_point() +
  ylab("Miles/(US) gallon") +
  xlab("Weight (1000 lbs)")
```

---

## Bring the Experimental Logic Back

What does experiments do? 

.center[<img src="images/controlTreatment.png" height = 400 />]

???

How to assign the groups?

---

## Why Randomization?

.center[<img src="images/balance-1.png" height = 500 />]

---

## What If You Cannot Randomize?

--

<img src="images/buyerSeller.jpg" height = 300, width = 320 />
<img src="images/matching.png" height = 300, width = 320 />

---

## In Practice

.left-column[<img src="images/fitOLS.gif" height = 400, width = 320 />]

--

.right-column[<img src="images/fitOLS_3d.png" height = 400, width = 320 />]

---

## An Illustration

Tang, Wenfang, Yue Hu, and Shuai Jin. 2016. “Affirmative Inaction: Language Education and Labor Mobility among China’s Muslim Minorities.” *Chinese Sociological Review* 48(4): 346–66.

---

## Why Is There An Inequality in Labor Mobility?

Puzzle: .magenta[Same] education level, but .magenta[different] labor mobility

<img src="images/han.jpeg" height = 300, width = 320 />
<img src="images/uyghur.jpg" height = 300, width = 320 />

---

## Theory

Affirmative inaction language policy reduces Uyghurs' labor mobility.

.center[<img src="images/uyghurStudent.jpg" height = 350 />]

---

## Hypothesis


H<sub>1</sub>: Education is .magenta[fairly equal] between the Han and the Uyghur groups.

--

H<sub>2</sub>: The linguistically distinctive Uyghurs are far less proficient in Mandarin than the Han majority.

--

H<sub>3</sub>: Hans enjoy a higher degree of socioeconomic status than the Uyghurs.

--

H<sub>4</sub> Language proficiency plays a favorable role in improving the socioeconomic conditions for the Uyghurs.

---

## Examination

.center[<img src="images/eduMan.png" height = 300 />]

--

.small[
H<sub>1</sub>: Education is fairly equal between the Han and the Uyghur. .magenta[&check;]  
H<sub>2</sub>: The Putonghua of Uyghurs are far less proficient.  
H<sub>3</sub>: Hans enjoy a higher socioeconomic level than the Uyghurs.  
H<sub>4</sub>: Language proficiency favors Uyghurs in promoting.
]

---

.center[<img src="images/eduMan2.png" height = 400 />]

--

.small[
H<sub>1</sub>: Education is fairly equal between the Han and the Uyghur. &check;  
H<sub>2</sub>: The Putonghua of Uyghurs are far less proficient. .magenta[&check;]  
H<sub>3</sub>: Hans enjoy a higher socioeconomic level than the Uyghurs.  
H<sub>4</sub>: Language proficiency favors Uyghurs in promoting.
]

---

.center[<img src="images/jobEth.png" height = 400 />]

--

.small[
H<sub>1</sub>: Education is fairly equal between the Han and the Uyghur. &check;  
H<sub>2</sub>: The Putonghua of Uyghurs are far less proficient. &check;  
H<sub>3</sub>: Hans enjoy a higher socioeconomic level than the Uyghurs. .magenta[&check;]  
H<sub>4</sub>: Language proficiency favors Uyghurs in promoting.
]

---

.center[<img src="images/sem.png" height = 400 />]

--

.small[
H<sub>1</sub>: Education is fairly equal between the Han and the Uyghur. &check;  
H<sub>2</sub>: The Putonghua of Uyghurs are far less proficient.&check;  
H<sub>3</sub>: Hans enjoy a higher socioeconomic level than the Uyghurs.&check;  
H<sub>4</sub>: Language proficiency favors Uyghurs in promoting. .magenta[&check;]
]

---

## Take-Home Points

.left-column[
### Do large-N analyses

1. Identify puzzle
1. Elaborate theory
1. Imply hypotheses
1. Design examination
1. Analyze data
1. Report findings
]

--

.right-column[

### Bonus

<img src="images/table.png" height = 400 />
]

