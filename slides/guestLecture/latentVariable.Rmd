---
title: "Learning Latent Variable Analysis with Dr. Hu (I)"
subtitle: "潜在变量分析I"
author: "胡悦"
institute: "清华大学政治学系"
# date: "2019-06-01"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: 
      - zh-CN_custom.css
      - styles.css
      - "https://use.fontawesome.com/releases/v5.6.0/css/all.css"
      - "https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css"
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)

library(pacman)

p_load("psych", "lavaan", "semPlot", "qgraph", "haven", "corrplot",  "tidyverse")
```


## 内容概要

* 潜在变量分析概述
* 什么是EFA
    + EFA诊断
    + EFA vs. PCA
* 什么是CFA
    + CFA诊断
* SEM 入门

---

## 操作语言

* R
    + [`psych`](https://personality-project.org/r/psych/vignettes/intro.pdf)
    + [`laavan`](https://lavaan.ugent.be/)

---

class: inverse, bottom

# 潜在变量分析：一种方法

---

## 潜在变量

.left-column[
<img src="images/lv_LoveLife.jpg" height = 400 />
]

???

Anna Kendrick's 2020 show, showing how difficult to find "the one." This "being loved" is a latent variable.

--

.right-column[

1. 不可见(Unobservable)
1. 多维度(Multidimensional)
1. 有效果(Consequential)

]

???

The latent variable per se can't be directly measured. But its consequences in opinions and behaviors can be observed.

---

## 为什么需要了解潜在变量？

公共舆论、政治文化、政治心理……几乎所有社会科学学科：

* 抽象
* 复杂
* 综合

--

> .red[Cornerstone] of successful scientific inquiry.  
---Delli Carpini and Keeter 1993

???

Delli Carpini, M. X., and S. Keeter. 1993. “Measuring Political Knowledge: Putting First Things First.” American Journal of Political Science 37 (4): 1179–1206.

---

## 怎么找？

例：测量个体的“社会资本”（social capital）

指标问题X（1~10）：

1. 您是否信任身边人？
1. 您在政府机关有没有亲戚
1. 您的朋友是否和您的想法经常一致？

$$\tilde{X} = (X_1 + X_2 + X_3)/3.$$

累加型综合法(additive scales)

---

看起来可能有用……

--

1. 平等权重(equal weight)
1. 数据敏感(extreme value sensitivity)
1. 忽略极化(polarity ignoring)

---

## "易求无价宝，难得有心郎！"

### 因素分析模型(Factorial Models)

1. 探索性因子分析(EFA)
1. 验证性因子分析(CFA)
1. 结构方程模型(SEM)

### 类型分析模型(Typological Models)

1. 项目反应理论(IRT)
1. 跨群组项目反应(MrP, GIRT, DCPO)

???

鱼玄机《赠邻女》：羞日遮罗袖，愁春懒起妆。易求无价宝，难得有心郎

---

class: inverse, bottom

# 因素分析综述

---

## 因素分析模型(Factorial Models)

1. 探索性因子分析(EFA)
1. 验证性因子分析(CFA)
1. 结构方程模型(SEM)

---

### 理论

.navy[可见]指标(indicators) &larr; .red[潜在]变量(variable)

???

uncover the underlying structure of a relatively large set of variables. 

--

.left-column[
### 实现

.red[Minimum] factors for the variances

a.k.a. 变量简化  
(降维打击？)
]

.right-column[
<img src="images/lv_jiangwei.jpg" height = 300 />
]

???

determine the minimum number of hypothetical factors or components that account for the variance between variables.

---

## 操作

.center[<img src="images/lv_efa.png" height = 500 />]

???

Known: I wanna fewer variables
Unknown: how many? how to combine?

---

class: inverse, bottom

# 探索性因子分析
## Exploratory Factor Analysis

---

## 理念背后

.center[.large[**X<sup>*</sup> = &Phi;&Lambda;' + &delta;**]]


**X<sup>*</sup>**: 潜在变量  
**&Phi;**: 指标选择  
**&Lambda;**: 单项贡献（a.k.a., factor loading）  
**&delta;** 选择误差

???

Quinn, Kevin M. undefined/ed. “Bayesian Factor Analysis for Mixed Ordinal and Continuous Responses.” Political Analysis 12(4): 338–53.

---

## 操作实现

1. 因子个数选择
1. Rotation
1. 因子合成
1. 结果检验

---

## 一个心理学案例

19,719 参与者, the "Big Five Personality" Test

变量名：
```{r data-big5}
df_big5 <- read_csv("data/lv_dataBIG5.csv")
df_big5[df_big5 == 0] <- NA
cat(names(df_big5))
```

???

经验开放性Openness, 尽责性Conscientiousness, 外向型Extraversion, 亲和性Agreeableness, 情绪不稳定型Neuroticism

https://quantdev.ssri.psu.edu/tutorials/intro-basic-exploratory-factor-analysis

---

## 因子个数选择

### 相关性分析

```{r corrplot, fig.align='center', fig.height=5.5}
df_big5 %>%
  select(8:57) %>%
  cor(use = "complete.obs") %>%
  corrplot(order = "hclust",
           tl.col = 'black',
           tl.cex = .75) 
```

---

### Horn's Parallel Analysis

```{r parallelAnalysis, fig.align='center', fig.height=6, results='hide'}
df_big5 %>%
  select(8:57) %>%
  fa.parallel(fa = "fa")
```

???

已知观测数据集**O**<sub>m&times;n</sub>

1. 创建随机数据集**R**<sub>m&times;n</sub>;  
1. 相关矩阵<sub>**R**</sub> 和 &lambda;<sub>**R**</sub>;  
1. 相关矩阵<sub>**Ok**</sub> 和 &lambda;<sub>**Ok**</sub> (k为因子数)
1. &lambda;<sub>**Ok**</sub> vs. &lambda;<sub>**R**</sub>

A. 如果&lambda;<sub>**Ok**</sub> < &lambda;<sub>**R**</sub>, 则 ~~k~~  
B. Kaiser criterion

&lambda;是相关矩阵特征值
Kaiser criterion: 特征值<1 不可

---

## 因子提取(Factor Extraction)

常见方法：

+ .navy[Minimum residual (OLS)]
+ Principal axes
+ Alpha factoring
+ Weighted least squares
+ Minimum rank
+ .red[Maximum likelihood] (ML, minimum &chi;<sup>2</sup> goodness of fit)

---

## Rotation

.center[<img src="images/lv_rotation.jpg" height = 400 />]

简化数据结构

???
Rotation:

A pattern of loadings where each item loads strongly on only one of the factors, and much more weakly on the other factors.

---

## 因子合成

```{r efa}
result_efa <- df_big5 %>%
  select(8:57) %>%
  fa(nfactors = 5,
     rotate = "oblimin",
     fm = "minres")

print(result_efa$loadings, cutoff = .296) # the point was picked for the purpose of presentation
```

---

## 成了吗？

### 常见诊断指标

1. Sum of squared (SS) loading<sup>1</sup>
1. Communality & Uniqueness
1. Root means square of residuals(RMSR)
1. Tucker-Lewis Indes (TLI)
1. Reliability test (Crobach's &alpha;)<sup>2</sup>

.footnote[
[1] 特征值  
[2] 为每个因子分别计算
]

???

SS：Kaiser criterion: &lambda; < 1 不可
Communality:  SS of all the factor loadings for a given variable
Uniqueness: 1 - Communality
RMSR < 0.05
TLI > 0.9

Crobach's &alpha;: 计算因子分布的variables是不是内部一致，除非发表，不大必要

---

## 因子在哪里？

"score"

```{r scores, fig.align='center', fig.height=6}
df_score <- result_efa$scores %>% 
  as_tibble()
hist(df_score$MR1)
```

---

class: inverse, bottom

# 验证性因子分析
## Confirmative Factor Analysis

---


## 探索性 vs 验证性：实现

.left-column[
### EFA: 数据指向

1. 实证观察（归纳）
1. 未知维度
    + 每个维度都产生影响
1. 多重指标
    + Loading大小之分
1. 无视测量偏差关联

]

.right-column[
### CFA: 理论指向

1. 理论定义（演绎）
1. 明确维度
    + 维度-指标关系明确
1. 单一指标
    + Loading有无之分
1. 允许测量误差具有关联
]

---

## CFA 指标选择

1. 严格依据理论
1. 每维度一指标

---

## CFA 指标选择

操作原则：

1. 每个维度一个指标，但维度拆分.navy[艺术>技术]

--

1. 效果.red[~~原因~~]指标

--

```{r causal, fig.align='center', fig.height=5}
DiagrammeR::grViz(
  "digraph {

graph[layout = dot]

node[shape = rectangle, style = filled, fillcolor = Linen]

s [label = '压力', shape = 'ellipse']
d [label = '家人\n去世']
j [label =  '丢失\n工作']
i [label = '身患\n疾病']

# edge definitions with the node IDs
s -> {d, j, i}
}"
)
```


---

## 模型建构

.center[<img src="images/lv_multitrait.png" height = 550 />]

???

裁判对滑雪运动员的评判

单侧: factor complexity = 1 （一个变量只贡献一个latent）  
双侧: factor complexity > 1

---

## 你最多能连多少线？：Identification

\begin{cases}
y = x + z\\
x = 2y - 3z
\end{cases}

--

.center[**X = &Lambda;<sub>X</sub>&xi; + &delta;**]

当**&Lambda;、&Phi;、&Theta;**存在唯一解时，模型是identified.

--

**t rule**:

t < q(q + 1)/2

t: 不可见
q：可见

???

Another way to calculate df.

---

## 成了吗？

### Overall: &chi;<sup>2</sup>

结果显著则说明整体模型可能有问题。

### Incremental Fit Indices

将模型与基线模型比较

### Tucker-Lewis Index (TLI) & Comparative Fit Index (CFI)

+ 1 理想情况
+ <.95 不可接受

???

CFI可以>1, 这种情况视为1

---

### Root Mean Square Error of Approximation (RMSEA) & Standardized Root Mean Square Residual (SRMR)

+ 0 理想情况
+ &le; 0.05 不错
+ 0.05 ~ 0.08 差强人意
+ &ge; 0.1 不可接受

---

## 实例：Holzinger & Swineford 1939

.left-column[
对初中生精神状况的调查：
+ 视觉因素：x<sub>1~3</sub>
+ 阅读因素：x<sub>4~6</sub>
+ 表达因素：x<sub>7~9</sub>
]

.right-column[
```{r diagram-cfa, fig.align='center', fig.height=8}
HS.model <- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '
fit <- cfa(HS.model, data = HolzingerSwineford1939)


semPaths(
  fit,
  layout = "tree",
  curve = 1,
  rotation = 4,
  nCharNodes = 0,
  mar = c(3, 20, 3, 20),
  border.width = 1.0,
  esize = 1.0,
  edge.color = "black",
  label.scale = FALSE,
  label.cex = 1.0,
  residuals = FALSE,
  fixedStyle = 1,
  freeStyle = 1,
  curvePivot = FALSE,
  sizeMan = 7,
  sizeLat = 10
)
```
]

---

```{r results-hsModel}
summary(fit, fit.measures=TRUE)
```

---

## 总结一下

* 潜在变量分析概述
    + .magenta[因素分析]
    + 类型分析
* 什么是EFA
    + 探索性因子分析：通过loading找到潜在变量
    + EFA诊断：Kaiser‘s criterion, reliability
* 什么是CFA
    + 验证性因子分析：检验潜在变量对于观察指标是否有影响
    + CFA诊断：&chi;<sup>2</sup>, TLI/CFI，RMSEA/SRMR

---

class: inverse, center, middle

# Questions, Comments, and Suggestions?

---

class: inverse, bottom

# 延申：结构方程模型
## Structural Equation Model

---

## 结构方程模型

+ Structural equation models (SEMs)
+ LISREL (Linear Structural ReLationships) models
+ Covariance structure models
+ Latent variable models
+ Structural equations with latent variables

---

## “老朋友”

Confirmative factor analysis  
Multiple regression  
Multivariate regression  
ANOVA  
General linear model  
Path analysis  
Recursive models  
Dichotomous and ordered probit  
Seemingly unrelated regressions  
Simultaneous models  
Latent growth curve models  
......

---

## CFA之上

与CFA相比，SEM：

+ 观察变量： X, .magenta[Y]

--

+ 模型建构：
    1. Latent variable model
    1. Measurement model (CFA)
    1. Relations among the errors 
    
--

+ 依然要求identification

---

## 估计

MLE

---

## 诊断

+ Overall：&chi;<sup>2</sup>
+ Incremental：
    + TLI & CLI
    + Incremental Fit Index(IFI, &Delta;<sup>2</sup>): 1理想，<0.9不可接受
+ Absolute:
    + RMSEA: < 0.06
    + BIC: 越小越好
    
---

实例：Bollen 1989

政治民主（1960，1965）与工业化

```{r diagram-sem, fig.align='center', fig.height=4, fig.keep="last"}

model <- '
  # measurement model
    ind60 =~ x1 + x2 + x3
    dem60 =~ y1 + y2 + y3 + y4
    dem65 =~ y5 + y6 + y7 + y8
  # regressions
    dem60 ~ ind60
    dem65 ~ ind60 + dem60
  # residual correlations
    y1 ~~ y5
    y2 ~~ y4 + y6
    y3 ~~ y7
    y4 ~~ y8
    y6 ~~ y8
'
fit <- sem(model, data = PoliticalDemocracy)
Graph <- semPaths(
  fit,
  #layout=L,
  layout = "tree2",
  nCharNodes = 0,
  curve = 1,
  rotation = 4,
  #mar=c(3,3,3,3),
  edge.color = "black",
  border.width = 1.0,
  esize = 1.0,
  label.scale = FALSE,
  label.cex = 1.0,
  residuals = FALSE,
  fixedStyle = 1,
  freeStyle = 1,
  curvePivot = FALSE,
  #style="LISREL",
  exoVar = FALSE,
  sizeMan = 7,
  sizeLat = 10,
  DoNotPlot = FALSE
)
L <- matrix(
  c(
    0.4 ,
    1 ,
    0.7 ,
    1 ,
    1.0 ,
    1 ,
    -1.0 ,
    1 ,
    -1.0 ,
    0.71 ,
    -1.0 ,
    0.43 ,
    -1.0 ,
    0.14 ,
    -1.0 ,
    -0.14 ,
    -1.0 ,
    -0.43 ,
    -1.0 ,
    -0.71 ,
    -1.0 ,
    -1    ,
    0.7 ,
    0.4 ,
    0.0 ,
    0.4 ,
    0.0 ,
    -0.4
  ),
  14,
  2,
  byrow = TRUE
)
qgraph(Graph, layout = L, arrowAngle = 0.5)
```

---

```{r results-semModel}
summary(fit, fit.measures=TRUE)
```

---

## 在操作SEM之前，你可能还想知道

1. SEM怎么对待Measurement errors
1. SEM怎么处理非线性变量(hint: GSEM)
1. SEM怎么对待群组效应
1. SEM如何处理缺失值(hint: 可能比MI还要好哦！)

--

1. .magenta[SEM 不能证明因果关系！！]
